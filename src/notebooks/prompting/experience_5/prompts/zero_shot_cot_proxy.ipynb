{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.sys.path.append(os.path.join(os.getcwd(), \"../../../..\"))\n",
    "from models.Prompt import PromptRunParameters\n",
    "from prompting.run_prompt import WrapperEnum, run_prompts\n",
    "from prompting.get_prompts import zero_shot_cot_proxy\n",
    "from prompting.get_themes_list import selected_level_1_themes_first_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system: Ton rôle est d'attribuer un thème à une question posée par un député à l'Assemblée nationale française. La liste des thèmes est la suivante :\n",
      "- A. retraites\n",
      "- B. ministères et secrétariats d'état\n",
      "- C. handicapés\n",
      "- D. enseignement\n",
      "- E. politique extérieure\n",
      "- F. agriculture\n",
      "- G. logement\n",
      "- H. anciens combattants et victimes de guerre\n",
      "- I. énergie et carburants\n",
      "- J. impôts et taxes\n",
      "- K. sécurité sociale\n",
      "- L. justice\n",
      "- M. entreprises\n",
      "- N. outre-mer\n",
      "- O. déchets, pollution et nuisances\n",
      "- P. communes\n",
      "- Q. commerce et artisanat\n",
      "- R. sports\n",
      "- S. consommation\n",
      "- T. famille\n",
      "- U. étrangers\n",
      "Le thème assigné doit être un des thèmes de la liste fournie. Seuls les thèmes de la liste précédente sont valides. Réfléchis étape par étape.\n",
      "\n",
      "user: {0}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "! ONLY EDIT THIS CELL\n",
    "\"\"\"\n",
    "\n",
    "# ? Defines the themes list and its associated hierarchy level (0 to 3)\n",
    "THEMES_LIST, THEMES_HIERARCHY_LEVEL = selected_level_1_themes_first_version()\n",
    "# ? Defines the list of prompts to use, its associated prompt type (zero-shot, one-shot, etc.)\n",
    "PROMPTS, ASSOC, ACCEPTED_THEMES_FOR_QUESTION, PROMPT_TYPES, VALIDATION_FUNC, RETRIEVE_THEME_FUNC = (\n",
    "    zero_shot_cot_proxy(THEMES_LIST, THEMES_HIERARCHY_LEVEL)\n",
    ")\n",
    "\n",
    "# ? Specify the API wrapper to use for calling the LLM\n",
    "WRAPPER = WrapperEnum.OpenAI\n",
    "# ? Define the model to use with the wrapper (available models can be found in the PROMPTING.md file)\n",
    "MODEL = \"gpt-4o-mini-2024-07-18\"\n",
    "# ? Set the temperature parameter for the model to control randomness (0.0 = deterministic, 1.0 = random)\n",
    "TEMPERATURE = 0.0\n",
    "\n",
    "# ? The identifier for the batch of questions being processed. Set to None if no Batch should be used\n",
    "BATCH_ID = \"66f9ca5824e5760146e27831\"\n",
    "# ? Number of questions sampled from the database. Will create a Batch based on the themes list\n",
    "QUESTION_SAMPLE_SIZE = 1500\n",
    "\n",
    "# ? Name for the run\n",
    "NAME = \"zero shot cot proxy\"\n",
    "# ? Add a comment to be able to identify each run\n",
    "DESCRIPTION = \"experience #5 zero shot CoT proxy\"\n",
    "# ? If the API calls starts to be slower, increase the sleep time\n",
    "SLEEP_TIME = 0\n",
    "# ? Number of run to create with the same parameters\n",
    "NUMBER_OF_RUNS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "! DO NOT EDIT THIS CELL\n",
    "\"\"\"\n",
    "\n",
    "PARAMETERS = PromptRunParameters(\n",
    "    temperature=TEMPERATURE,\n",
    "    model=MODEL,\n",
    "    types=PROMPT_TYPES,\n",
    "    theme_hierarchy_level=THEMES_HIERARCHY_LEVEL,\n",
    "    wrapper=WRAPPER,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [44:06<00:00,  1.76s/it]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "! DO NOT EDIT THIS CELL\n",
    "\"\"\"\n",
    "for i in range(1, NUMBER_OF_RUNS + 1):\n",
    "    run_prompts(\n",
    "        parameters=PARAMETERS,\n",
    "        prompts=PROMPTS,\n",
    "        themes_list=THEMES_LIST,\n",
    "        number_of_questions=QUESTION_SAMPLE_SIZE,\n",
    "        batch_id=BATCH_ID,\n",
    "        accepted_themes_for_questions=ACCEPTED_THEMES_FOR_QUESTION,\n",
    "        description=DESCRIPTION,\n",
    "        name=NAME,\n",
    "        sleep_time=SLEEP_TIME,\n",
    "\t\tvalidation_func=VALIDATION_FUNC,\n",
    "        retrieve_theme_func=RETRIEVE_THEME_FUNC,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
