{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.sys.path.append(os.path.join(os.getcwd(), \"../../../..\"))\n",
    "from models.Prompt import PromptRunParameters\n",
    "from prompting.run_prompt import WrapperEnum, run_prompts\n",
    "from prompting.get_prompts import zero_shot_verbalized_confidence_vanilla\n",
    "from prompting.get_themes_list import selected_level_1_themes_first_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system: Ton rôle est d'attribuer un thème à une question posée par un député à l'Assemblée nationale française. La liste des thèmes est la suivante :\n",
      "- retraites\n",
      "- ministères et secrétariats d'état\n",
      "- handicapés\n",
      "- enseignement\n",
      "- politique extérieure\n",
      "- agriculture\n",
      "- logement\n",
      "- anciens combattants et victimes de guerre\n",
      "- énergie et carburants\n",
      "- impôts et taxes\n",
      "- sécurité sociale\n",
      "- justice\n",
      "- entreprises\n",
      "- outre-mer\n",
      "- déchets, pollution et nuisances\n",
      "- communes\n",
      "- commerce et artisanat\n",
      "- sports\n",
      "- consommation\n",
      "- famille\n",
      "- étrangers\n",
      "- collectivités locales\n",
      "Ta réponse doit deux choses :\n",
      "- Le thème correspondant, par exemple `retraites` ou `ministères et secrétariats d'état`. Le thème assigné doit être un des thèmes de la liste fournie. Seuls les thèmes de la liste précédente sont valides.\n",
      "- La probabilité que le thème choisi soit adéquat (entre 0.0 et 1.0)\n",
      "Ne fournis que ces deux éléments, aucune autre explication ou mot complémentaire.\n",
      "Par exemple: \n",
      "\n",
      "Thème: <le thème le plus adéquat pour annoter la question choisi parmi la liste fournie>\n",
      "Probabilité: <la probabilité comprise entre 0.0 and 1.0>\n",
      "\n",
      "user: {0}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "! ONLY EDIT THIS CELL\n",
    "\"\"\"\n",
    "\n",
    "# ? Defines the themes list and its associated hierarchy level (0 to 3)\n",
    "THEMES_LIST, THEMES_HIERARCHY_LEVEL = selected_level_1_themes_first_version()\n",
    "THEMES_LIST.append(\"collectivités locales\")\n",
    "# ? Defines the list of prompts to use, its associated prompt type (zero-shot, one-shot, etc.)\n",
    "(\n",
    "    PROMPTS,\n",
    "    ASSOC,\n",
    "    ACCEPTED_THEMES_FOR_QUESTION,\n",
    "    PROMPT_TYPES,\n",
    "    VALIDATION_FUNC,\n",
    "    RETRIEVE_THEME_FUNC,\n",
    ") = zero_shot_verbalized_confidence_vanilla(THEMES_LIST, THEMES_HIERARCHY_LEVEL)\n",
    "\n",
    "# ? Specify the API wrapper to use for calling the LLM\n",
    "WRAPPER = WrapperEnum.OpenAI\n",
    "# ? Define the model to use with the wrapper (available models can be found in the PROMPTING.md file)\n",
    "MODEL = \"gpt-4o-mini-2024-07-18\"\n",
    "# ? Set the temperature parameter for the model to control randomness (0.0 = deterministic, 1.0 = random)\n",
    "TEMPERATURE = 0.0\n",
    "\n",
    "# ? The identifier for the batch of questions being processed. Set to None if no Batch should be used\n",
    "BATCH_ID = \"670e8f917a833c48cc93d0cd\"\n",
    "# ? Number of questions sampled from the database. Will create a Batch based on the themes list\n",
    "QUESTION_SAMPLE_SIZE = 1500\n",
    "\n",
    "# ? Name for the run\n",
    "NAME = \"zero shot verbalized confidence w/ collectivités locales\"\n",
    "# ? Add a comment to be able to identify each run\n",
    "DESCRIPTION = \"experience #7 zero shot verbalized confidence w/ collectivités locales\"\n",
    "# ? If the API calls starts to be slower, increase the sleep time\n",
    "SLEEP_TIME = 0\n",
    "# ? Number of run to create with the same parameters\n",
    "NUMBER_OF_RUNS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "! DO NOT EDIT THIS CELL\n",
    "\"\"\"\n",
    "\n",
    "PARAMETERS = PromptRunParameters(\n",
    "    temperature=TEMPERATURE,\n",
    "    model=MODEL,\n",
    "    types=PROMPT_TYPES,\n",
    "    theme_hierarchy_level=THEMES_HIERARCHY_LEVEL,\n",
    "    wrapper=WRAPPER,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [32:04<00:00,  1.28s/it]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "! DO NOT EDIT THIS CELL\n",
    "\"\"\"\n",
    "\n",
    "for i in range(1, NUMBER_OF_RUNS + 1):\n",
    "    run_prompts(\n",
    "        parameters=PARAMETERS,\n",
    "        prompts=PROMPTS,\n",
    "        themes_list=THEMES_LIST,\n",
    "        number_of_questions=QUESTION_SAMPLE_SIZE,\n",
    "        batch_id=BATCH_ID,\n",
    "        accepted_themes_for_questions=ACCEPTED_THEMES_FOR_QUESTION,\n",
    "        description=DESCRIPTION,\n",
    "        name=NAME,\n",
    "        sleep_time=SLEEP_TIME,\n",
    "\t\tvalidation_func=VALIDATION_FUNC,\n",
    "        retrieve_theme_func=RETRIEVE_THEME_FUNC,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
