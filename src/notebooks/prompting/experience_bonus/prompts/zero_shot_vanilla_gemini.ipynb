{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.sys.path.append(os.path.join(os.getcwd(), \"../../../..\"))\n",
        "from models.Prompt import PromptRunParameters\n",
        "from prompting.run_prompt import WrapperEnum, run_prompts\n",
        "from prompting.get_prompts import zero_shot_vanilla\n",
        "from prompting.get_themes_list import selected_level_1_themes_first_version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "system: Ton rôle est d'attribuer un thème à une question posée par un député à l'Assemblée nationale française. La liste des thèmes est la suivante :\n",
            "- retraites\n",
            "- ministères et secrétariats d'état\n",
            "- handicapés\n",
            "- enseignement\n",
            "- politique extérieure\n",
            "- agriculture\n",
            "- logement\n",
            "- anciens combattants et victimes de guerre\n",
            "- énergie et carburants\n",
            "- impôts et taxes\n",
            "- sécurité sociale\n",
            "- justice\n",
            "- entreprises\n",
            "- outre-mer\n",
            "- déchets, pollution et nuisances\n",
            "- communes\n",
            "- commerce et artisanat\n",
            "- sports\n",
            "- consommation\n",
            "- famille\n",
            "- étrangers\n",
            "Ta réponse doit contenir une seule chose: le thème correspondant, par exemple `retraites` ou `ministères et secrétariats d'état`. Le thème assigné doit être un des thèmes de la liste fournie. Seuls les thèmes de la liste précédente sont valides.\n",
            "\n",
            "user: {0}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "! ONLY EDIT THIS CELL\n",
        "\"\"\"\n",
        "\n",
        "#? Defines the themes list and its associated hierarchy level (0 to 3)\n",
        "THEMES_LIST, THEMES_HIERARCHY_LEVEL = selected_level_1_themes_first_version()\n",
        "#? Defines the list of prompts to use, its associated prompt type (zero-shot, one-shot, etc.)\n",
        "PROMPTS, ASSOC, ACCEPTED_THEMES_FOR_QUESTION, PROMPT_TYPES = zero_shot_vanilla(THEMES_LIST, THEMES_HIERARCHY_LEVEL)\n",
        "\n",
        "#? Specify the API wrapper to use for calling the LLM\n",
        "WRAPPER = WrapperEnum.Google\n",
        "#? Define the model to use with the wrapper (available models can be found in the PROMPTING.md file)\n",
        "MODEL = \"models/gemini-1.5-pro\"\n",
        "#? Set the temperature parameter for the model to control randomness (0.0 = deterministic, 1.0 = random)\n",
        "TEMPERATURE = 0.0\n",
        "\n",
        "#? The identifier for the batch of questions being processed. Set to None if no Batch should be used\n",
        "BATCH_ID = \"66f9ca5824e5760146e2783a\"\n",
        "#? Number of questions sampled from the database. Will create a Batch based on the themes list\n",
        "QUESTION_SAMPLE_SIZE = 1500\n",
        "\n",
        "# ? Name for the run\n",
        "NAME = f\"zero shot {MODEL}\"\n",
        "#? Add a comment to be able to identify each run\n",
        "DESCRIPTION = f\"experience #bonus zero shot vanilla {MODEL}\"\n",
        "#? If the API calls starts to be slower, increase the sleep time\n",
        "SLEEP_TIME=5\n",
        "#? Number of run to create with the same parameters\n",
        "NUMBER_OF_RUNS=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "! DO NOT EDIT THIS CELL\n",
        "\"\"\"\n",
        "\n",
        "PARAMETERS = PromptRunParameters(\n",
        "    temperature=TEMPERATURE,\n",
        "    model=MODEL,\n",
        "    types=PROMPT_TYPES,\n",
        "    theme_hierarchy_level=THEMES_HIERARCHY_LEVEL,\n",
        "    wrapper=WRAPPER\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 43%|████▎     | 651/1500 [56:33<1:13:45,  5.21s/it]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m! DO NOT EDIT THIS CELL\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, NUMBER_OF_RUNS \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m----> 6\u001b[0m \t\u001b[43mrun_prompts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPARAMETERS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43mprompts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPROMPTS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43mthemes_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTHEMES_LIST\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43mnumber_of_questions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mQUESTION_SAMPLE_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43mbatch_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_ID\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43maccepted_themes_for_questions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mACCEPTED_THEMES_FOR_QUESTION\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDESCRIPTION\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43msleep_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSLEEP_TIME\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m\t\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Epitech/msc/parl-ia-ment/article/src/notebooks/prompting/experience_bonus/prompts/../../../../prompting/run_prompt.py:338\u001b[0m, in \u001b[0;36mrun_prompts\u001b[0;34m(parameters, prompts, themes_list, description, name, accepted_themes_for_questions, batch_id, number_of_questions, retrieve_theme_func, response_format, sleep_time, validation_func, dry_run)\u001b[0m\n\u001b[1;32m    333\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning #\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minserted_prompt_run\u001b[38;5;241m.\u001b[39minserted_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with batch #\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    335\u001b[0m )\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m question \u001b[38;5;129;01min\u001b[39;00m tqdm(question_list):\n\u001b[0;32m--> 338\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43msleep_time\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    339\u001b[0m     run_prompt(\n\u001b[1;32m    340\u001b[0m         question\u001b[38;5;241m=\u001b[39mquestion,\n\u001b[1;32m    341\u001b[0m         prompt\u001b[38;5;241m=\u001b[39mprompt,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    347\u001b[0m         dry_run\u001b[38;5;241m=\u001b[39mdry_run,\n\u001b[1;32m    348\u001b[0m     )\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m PromptRunInfo(\n\u001b[1;32m    351\u001b[0m     run_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(inserted_prompt_run\u001b[38;5;241m.\u001b[39minserted_id),\n\u001b[1;32m    352\u001b[0m     prompts\u001b[38;5;241m=\u001b[39mprompts,\n\u001b[1;32m    353\u001b[0m     prompt_run\u001b[38;5;241m=\u001b[39mprompt_run,\n\u001b[1;32m    354\u001b[0m )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "! DO NOT EDIT THIS CELL\n",
        "\"\"\"\n",
        "\n",
        "for i in range(1, NUMBER_OF_RUNS + 1):\n",
        "\trun_prompts(\n",
        "\t\tparameters=PARAMETERS,\n",
        "\t\tprompts=PROMPTS,\n",
        "\t\tthemes_list=THEMES_LIST,\n",
        "\t\tnumber_of_questions=QUESTION_SAMPLE_SIZE,\n",
        "\t\tbatch_id=BATCH_ID,\n",
        "\t\taccepted_themes_for_questions=ACCEPTED_THEMES_FOR_QUESTION,\n",
        "\t\tdescription=DESCRIPTION,\n",
        "\t\tname=NAME,\n",
        "\t\tsleep_time=SLEEP_TIME\n",
        "\t)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
